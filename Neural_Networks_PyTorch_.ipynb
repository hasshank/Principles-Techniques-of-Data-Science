{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTG-z8liU6Ud"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_circles, make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import SGD, Adam\n",
        "\n",
        "from ipywidgets import interact, IntSlider, FloatSlider, Dropdown, Checkbox\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaEBS9MVVn8V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "d568c07e-92ea-40ff-b55f-a9de04dad350"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d9061350-1b45-4435-986e-b887373b9c2b\" class=\"plotly-graph-div\" style=\"height:500px; width:500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d9061350-1b45-4435-986e-b887373b9c2b\")) {                    Plotly.newPlot(                        \"d9061350-1b45-4435-986e-b887373b9c2b\",                        [{\"marker\":{\"color\":\"red\"},\"mode\":\"markers\",\"name\":\"0\",\"x\":[0.4710616235290077,-0.029093660091882523,0.5235320396867599,-0.9776122190942852,-0.6140170855453289,-0.4756970801550467,0.14294008341214876,-1.0945847675025577,-0.680332988236764,0.22753623482244384,-0.07923121445503062,-0.50146667486098,1.0340398849199888,-0.24095918801952876,-0.7578842302867491,0.7875619038729035,-0.8251646480481274,0.39318854909428225,-0.7295812100205271,-0.9339566159800944,-0.7287912424518134,0.9743341342030503,-0.8295736036744782,0.7550833549082977,0.7699543717231982,0.8566014587677364,-1.090837683503508,-0.32354267210407495,1.056178755375081,-1.105689427724513,0.7344871890607804,0.08337674025747518,1.0158827646706394,-0.7011506355681143,-0.835360825403936,0.7508445628114545,-1.0025516269259283,0.8266031219785007,-0.7017175689892362,0.3153179841841191,-0.4622212177184093,-0.8931875463220218,0.48896600567873355,0.722509706678197,-1.1209834256785445,0.7703760965761592,0.1615102226582631,0.39784692145344314,0.11922134977599341,-0.8756455273943422,-0.11943406305535026,0.6836176677706725,0.8199254592956708,-0.41807908544010425,-0.6872975348669839,0.8135991397995015,-1.27314668578737,-1.1951829190532959,0.640396274464418,-1.0842587662286836,0.5959871173015869,0.002718421911587582,-1.1060502310827187,0.5643208560736415,0.40374399715490084,0.8178498711653688,-0.5373449215593518,-1.2390692743659266,-1.0718387539359278,-0.5589676433836568,0.06856883729287894,0.5551843562708282,0.7180251570811055,-1.0872225143496792,0.5607868678118405,-0.7424090790003516,-0.4919491408570886,-0.8588068924021475,-0.24908773269473528,0.8274735746172006,0.2710318255429246,1.1481148737044153,-0.1452971694350399,-0.8480761027904876,-0.694584561416526,1.238955289081907,-0.012144383429280831,-0.2462519626599273,-0.17526943380724097,-0.1515409149641029,-0.8460495405619899,-0.9167594842128576,0.157454479529491,-0.33486182602943837,-1.0060978032750836,0.746976167544713,1.0354293045789102,-0.68789717466202,0.726372489083601,0.36626617642943093,-0.32663098757307846,-0.32047032546816323,-1.004756439623442,-0.6655354870429991,0.7805368572936868,1.1974607367451036,-0.25391488190529693,-0.4956717503358151,0.932041107601008,0.8413368492564716,0.7187619574604265,-0.8478944233450928,-0.9325838269533017,-0.7291886457360223,0.8988383294017644,-0.6193188196092082,-1.0748038832905422,0.17863159542694174,0.31083353364029326,0.7273685974799509,0.5992993201109833,-0.6240445529905851,0.5947646348798011,-0.16186602599286393,-0.8390439073157484,0.6868469983302925,0.8529769639499746,0.4744277652759161,-1.147532550607824,-0.054854958952374605,0.0021288271421240276,0.08500382918509387,0.965931506760528,0.0498523191142672,-0.9721314812757471,0.5734275382296248,-0.9526890543745267,0.5804884604802812,-0.7978683198738252,-0.9660908455658227,-0.842778028400477,-0.4176286001733377,0.6472413203875012,-0.7574932743617724,1.0436985063233861,0.0953141404801914,0.9443318391237305,0.4408269132903649,0.685588195579965,-0.6267536174139096,0.9469016004247042,0.5247077271753894,0.5687040409426728,-0.20365040363170495,0.4115697664308635,1.133499411713729,-1.0826923846304284,-0.3118728831414782,-0.5188111486474499,0.5784895881340382,-0.005536321857901649,-0.9097830496866695,-0.30297901548847134,1.2121711963814317,0.04907133000070127,-0.3563944155481757,1.1048725494505822,-0.7461543364106217,1.0414301518933335,0.06928811307056287,-0.3615988257957675,0.06053706979919724,-0.08811018166942436,0.3156709384116598,0.3014156314637944,-0.554530694493224,-1.1893851961189061,0.5949562491816998,-0.8508970109108276,-0.27346528325547353,-0.9920088079314866,0.8942657084990862,-0.31477080849348776,-0.34328081728708465,0.5818683003214283,-0.27516908169013043,0.703523129652176,-0.3699567229228475,0.7246149900067537,-0.7368140998948178,-0.006982574672962427,-0.35790988536218554,-0.2643496909751497,-0.6549863903782158,1.1108471015118448,0.724445109857673,0.4006151144233459,-0.49567621756637725,-0.3787724941068536,-1.054197633042827,-0.8282249518259515,-0.031191312862711783,-0.8222804569212774,0.7574539491842571,0.2724970527940793,0.4555827857345561,0.46802994970375994,0.5371465774245303,1.1964264064388435,1.090969874566126,-0.8404148177487983,0.5629549938888294,-0.7560990436215349,0.5480304042790579,0.9922562122661797,1.024660406710602,0.46982837884219186,0.035691361007881034,0.4133412701156331,0.7768177301092655,-0.8406014514293623,-1.1553448549391185,-0.13114540213183404,-0.13250401885896673,0.7343228873492225,-0.6476101196376507,1.1378119949499947,-0.827333062689939,0.02351297160425643,-0.8271020213194122,-0.420185206991344,0.2303665310025141,-0.3606911778047641,-0.5396021721939059,-0.12447563899816079,0.3982896082916503,0.7635958861965403,0.4078220838811447,0.0844530047420957,0.3164381192384387,-0.15218102241154322,0.41278528997345754,0.9753380456748261,0.0746057410325549,0.7391248986997603,0.47333906869314496,-0.027853627472877285,0.5693442560892443,0.4357488531139615,0.17448234856185596,0.9535385722109888,0.9018929844353282,-0.17403319000034256,-0.5735456389913215,1.2287713386789105,0.20346162152575958,0.21871201479606095,-0.4112668236597734,0.6886764650929398,0.4543051310040033,-0.4278949003121122,0.31964558359889483,-0.06769457128021114,-0.9758047516052705,-0.43233819854045463,1.1227685645589018,-0.6198148413513598,-1.1608137611130782,-0.8943228234214313,0.8003437066814085,-0.32185042040019507,-0.48488753959438274,0.7229523730025462,-0.9202719430065892,0.2492216461273666,0.527137628155347,-1.0519127130179367,0.3861072016089919,-0.41673760401543625,0.651279639238691,0.7951317157656721,-0.9062250254891806,-0.7577038876863516,-0.7226697552590629,0.6205322545288949,0.17287587785651193,0.1541954279485203,0.05974701726979685,0.8336890569911137,0.714345646070222,0.028932252591218607,-0.9215156638185147,1.0672747366280295,-0.5587458662832167,-0.7639683444676478,-0.62511071244803,0.6935190759613046,-0.7966961254782606,-0.5140480594317737,-0.4100985368568513,-0.11997671448923347,0.5053272055819994,-0.29355657579676825,-0.13752018052561205,1.1687113147538557,0.21662823267370052,-0.36225075511189825,0.5844086701789497,0.4459132255431899,0.9163021341190944,-0.537197889439457,-1.0355335524392462,-0.2245357614758605,-0.8259385273874956,1.1872902427899763,0.06053249705136186,-0.43736576858997733,-0.8511657933159722,-0.6594625521897968,0.17836433902408175,-0.3426127792510737,-0.6244063573505327,1.3025047103177676,-0.47929140904355716,-0.45598767781711524,0.8009885277665629,1.0404285142430416,0.9892919888565098,-0.918952773774131,-0.7847866628825027,1.101502617395429,0.7316235027303604,-0.30424906730827217,-1.1430112179787493,1.1981211237176481,0.23271498889072392,1.160312227882442,-0.22682053628376952,-0.8122448018229769,-0.01569024594584023,0.18493876307221735,-1.2373982283808485,0.495012407913878,0.22061631001936638,0.9034521998713635,-0.2854294788277029,0.767601617953219,-0.2730283017345678,0.03670961931985317,-0.8208666137726537,0.7426600502502784,1.0916895886398796,0.789160000335769,-0.9409171202405862,-0.3941501777044094,-1.121748827675957,-0.8332902635288443,0.5217586096480455,-0.5986282687830855,1.2218129485795912,-0.30000280059606377,0.2058073745671633,-0.5116895270580668,0.7867187564661815,-0.4847767176372357,-0.6093773435931886,0.16455066662499201,-0.38831902683912156,-0.8244979701260249,-0.928290785014581,-0.9501804473258186,0.6000212389275801,0.0018480877448567162,-0.6982847420361576,-1.0231385650643716,0.886119514563443,-1.0297218769732728,0.42607543993952,0.3872534476950716,0.11174888101242833,-1.2917454397357448,0.09253811644988785,-0.8728193873185915,0.5264357139396763,1.0393975453198325,0.07501520034616453,-1.541030786941819,-0.10446252740772054,-0.7830798572928213,-0.45097668030055993,0.4642378871934518,-0.517070927968746,-1.0385581926209442,-0.5166502545992225,0.22328851973208458,0.13700774611137512,-0.9946373299326725,1.1364676915254748,-0.21059894371904894,0.42915791334557973,-0.9289380168187759,-0.4068031979914941,0.7988394985735217,-0.09829682006899254,0.4006734356539571,-0.9867784898923707,0.9227378699922706,-0.7252694352264486,0.07287283435241407,0.24218673007765226,-1.0668396171246524,0.7299140625333801,0.02477001811677132,0.6619892757336463,0.9124015099443401,0.8100876082267681,-0.5558910872578211,-0.20856983327670445,1.1503999936408502,-0.9466890403191732,0.8758870077891016,-0.10861249810933132,-1.094123382994694,0.7579142477318324,-0.012749450518868055,0.9076315089666354,0.1293092098127045,0.5918504901405732,1.2947619041429013,0.07600586238498508,0.9100417177609748,1.2020571693355047,-0.46430580766611285,0.7691148509620053,0.7351276881210868,0.26188572756855133,-0.5759276616836828,-0.8192693372470281,0.7819326003695131,-0.42093837607864887,-1.0436062633354284,-0.9246062411759912,1.1046069578613469,0.8582772952702251,-1.108672972486555,-0.9570701606304862,-0.07444697625437802,0.5983950920177286,1.2589323922085436,-0.01697310312815542,0.04647159838556483,0.7782695518406187,0.5533424387697143,-0.8610047805568737,0.9495714232040379,0.29293440380800057,0.9686483255520435,-0.15583845590349757,0.747239000618211,-0.6100289121065928,-0.39007845344790626,-1.1664895247028446,1.0499940095295943,-1.005640123872498,0.15338709794312513,-0.6448738372334455,-0.33122114158452953,1.0614304088593112,-1.0331417536753333,-0.29203240118569146,1.0587213207745387,0.9045750187828017,0.9975103735358,-0.9725404711737002,0.8265100446865978,-0.9042127495463356,0.8901049059738138,-0.8547398320751203,-0.7373043164765103,-0.9666207609579578,0.26686051830600177,0.17944506239777552,1.0771460502167658,-0.3564101130754469,-0.9665458365182815,-0.2701940334068667,0.16501235371506748,-0.016540286781063587,0.17605507378453333,0.8347060528864992,-0.6832240310623474,-0.8768951085647253,0.4916845247599507,0.31858447076816815,0.9686722599661401,0.7374671300544917,0.2868663471484485,-1.0357293601125754,0.58997682145876,0.2586018613661475],\"y\":[-0.8815264677372411,1.197445611112771,1.0058626382494658,-0.20350355753567653,-0.6486551761175195,1.0658046617635288,-0.9823259823754579,0.31835338624953635,0.267788210595109,1.1206922816636966,-0.732608352486845,1.0407571987128452,0.15454703978662873,-1.4629706607187518,1.1366446143743154,0.4473819224896832,-0.4532302767709654,0.9543480309725517,-0.5464353162755589,-0.6042528750005766,-0.4493796648055863,-0.857348149221283,-0.1692330693575284,0.38835312419960066,0.33521742107473873,0.1551905462587998,0.4912679724626059,-0.7678152376542733,0.09582108988082605,0.5334677011760616,0.615979814321095,0.8288638427969999,-0.11392022574818492,-0.6917059565493413,-0.4201528306577552,0.2832327957206684,-0.8198468375639256,0.4549082482898184,-0.742992531783119,0.6369566984324003,-0.7604430308634185,-0.7131598665665273,-0.8526152931845625,-0.47218522089590964,0.49343294475366706,-1.1942533067847965,1.010045826124461,0.5518478677258746,-1.0157752724440945,-0.37916280212516823,0.8480737256678503,0.9062123602123672,-0.6305189887941169,0.9499550875409163,-0.49840509911209585,-0.8251001491167461,-0.025126564860835282,0.4182225310425164,-0.42871480789137895,-0.6843036304028878,0.7961555781447605,0.8370693450962066,0.2155968999994351,0.06753782804567249,0.9228130794280481,0.3600576613578035,-0.09508920003939861,-0.36498650270708755,-0.15938723587449244,-0.8537728317714768,1.1028088329342465,-0.6617022263357653,-0.4386328008938616,-0.9268008682067933,0.6828914910186789,-0.42426754636652836,-0.4139712646397239,-0.5884346844465392,-1.1512761319850588,-0.16185040277759166,1.062369656576376,-0.47290167090513724,-0.9706605151125561,-0.32029400056833446,-0.07013029998777962,-0.3636256551406558,-1.0806173539447093,1.0142122842112704,-1.0737442385912226,-1.3991627494395786,0.36851325731083084,0.5750367165507475,-0.5832137819312693,-0.8988400898799179,0.3697989854132323,0.7620007335352869,0.3506269018782768,0.8663533781140466,-0.12601009321661866,0.8419088399286427,1.179005499720518,-1.069720271007371,-0.10163490404456225,-0.2810989716636162,0.4311972862962242,0.14979205677425825,-1.11076557941639,-0.7072752104775033,0.026956648322512877,0.44381631493181173,0.27391944801255713,0.4623638845316247,0.8166770195097,-0.7510679395874879,0.0800091767460132,0.52424766091813,-0.24670854106341722,1.3360208949775754,-0.8850669276854942,0.8593875185137643,0.6194221079108743,-0.2817125474994752,0.7204045999772908,-0.9114818232464356,-0.7301457302087263,0.008311325429351576,-0.17904190728986502,0.660334590216272,-0.09557709640756544,-0.730026689809201,-0.9220814910402468,-1.1346675905285322,-0.33232420647073035,1.0858116678663448,0.09050697836426708,0.7004069543070364,0.7083693659615161,0.7208517743256739,0.1993144417748484,-0.4682539669267136,0.5605496191492815,-0.6536298819278725,-0.5385793191222833,0.23454325377708612,-0.3100363802079531,-1.0389659291988926,-0.5971085334630193,-0.4757760690386904,0.027143999435303608,0.8095816932875791,-0.3777514817587749,-0.3608692270196052,-0.6053724939927363,-1.234997729448113,-0.528562564524844,-0.40225897865268256,-0.04441040760169279,-0.990366564636718,0.5040364041131448,0.6500824302753772,0.9434929556553726,-0.5951926189642823,-1.174516356473686,-0.24756211845799653,0.854784681208083,-0.8592921020659579,-0.1469820828955599,-0.6468055506091388,-0.43948006753527125,-1.3169502274924172,1.0514057264924834,0.8931703300623807,-0.8589626404136692,-0.9865876504541226,1.045101665433864,1.1860137009366258,-0.5437352018330562,1.1078092794552,-0.6289047979561082,1.1230416172379714,-0.5715298837390678,-0.8776953292914582,-1.0592479486624653,0.6902029276716907,-0.6675169616851105,1.0371832520522912,-0.5154499352077423,0.9987704184317658,0.1666937028172033,0.7982035801242917,-1.3068898037482186,0.8572478572444266,1.0750817073133805,1.0567931470757852,0.1952456281842315,-0.3435551468624376,1.0566041017655783,0.09019753224225883,1.0745217877097195,0.001247327307188184,0.3789222363738363,0.8374772303764378,0.7164372361809226,0.41054111028845475,0.8516824262174036,0.8295430114212776,-0.4720400721287168,-0.7078039649006579,0.23371157572478932,-0.2504667555552206,-0.4817297008280535,0.5898872805262081,-0.39918753207935354,-0.6053225337129594,0.5686964820863751,-0.3029711730997455,-1.011524759761637,-0.7633880485764982,0.7767127196628594,0.5520827704641684,-0.010720158253704148,-0.526271788947196,-1.167411420683562,-0.7204562213880076,-0.5174562419158888,0.015211391829282661,0.2689114237594789,0.8260932608276719,-1.0382076408553818,0.3623594095683419,0.9484567915684075,-1.272914102080852,1.0328591726491005,0.24021670806434495,-0.9043820006745088,-0.8977661213133585,0.6162243643724402,0.9040893525208054,-1.2043319280306086,1.2563437678316225,0.7691997894509828,-1.0279921820989746,-0.4466954332075789,-0.6186668186937465,0.7650600626648947,0.7322528245621893,-0.941494671900933,1.0614840968432433,0.2979776186105305,-1.1425901296996086,0.24134712934307034,0.6189748148743752,-1.0528660738871678,0.9162560117321312,-0.098534958904297,1.1053443146783184,-0.7675073124383978,0.7472993904508272,-0.5667017050577297,-0.5920837984213765,0.9496122358730388,-1.188155632798476,-1.179517054926667,-0.31405647484913196,-0.8588404684607818,0.2067312935775479,-0.9223694398559018,0.4580540266521377,1.2614205012987498,0.20989896666901597,-1.0799987304484024,-0.8743639497506945,-0.4001415484927442,0.9588774743481882,0.9349858689432476,0.7424750187555589,-0.5164627914786775,-0.7185143670869131,1.0410169578398647,0.802633295446275,-0.45143440500414656,0.7015704945265423,-0.15975668764655698,0.06139459300840895,-0.12250680440374603,1.2686354078758353,0.9143699067944657,1.0902964081429292,-0.43596295850958666,0.42394786354222874,-0.9959967885521239,-0.23327612551515453,0.8328627529777695,-0.9981486934151949,0.5840410473458253,-0.09248013004392167,-1.0476410410149768,-1.0757013409946015,-0.7115682629024371,0.8727228129261596,0.5939862706558996,0.836555838809736,-0.717001201952511,0.8192548585411379,-0.5924006802996349,-0.8500116092180092,-0.568004042565022,0.26166839094759614,-0.7901554896216164,0.6796993819737499,0.7963277815861183,-0.1257225587593,0.8570335990062172,-0.5775374862173461,0.03921686563789342,1.1795113320207984,-0.7433982653422909,-0.1926567819133922,0.9172488595196859,1.120500808306788,0.7001106278050945,-0.5519030783049516,0.5572352713947394,0.4786816640893566,0.5895159815480249,0.06582794154789667,0.45176293042524573,-0.6811337313484132,-0.1876771731856603,0.2727213284591083,0.6272083587231033,-0.8344902502406689,-1.4322917495143916,0.1994652765524225,0.35019572611575916,-0.7685017671110244,-0.7265758014052717,0.5499257263513098,0.75520405870398,1.0989038813409406,0.9522954921988466,0.5397048634141632,0.7253464339327796,-0.5830305507223937,-0.9434136855249715,0.9261614434379564,0.6636560981025499,1.1278828551421154,-1.235989263643933,0.2783809458635276,-0.07264613041858373,0.07217095727078504,-0.7889018553649169,0.14220281155971445,-0.3923879644553828,0.02440829701793587,-0.47877103697518775,-0.6731118833357792,0.7825079982921652,-0.1911165850578017,1.162740983622743,1.0038381737130821,-1.079782436252684,-0.2770597951648965,-0.6658853454233691,0.601540992438579,1.2361749546043608,0.9697213011704563,0.5081716787249364,-0.23469039024190286,-0.5583282961104791,-0.9504396909301482,1.015792012505227,0.6040266868335373,0.41458268109675545,-0.8286310207425315,0.19039157520634914,-0.7496344170751329,0.7406640596974503,-0.7865540143017123,0.374162322403205,-0.8392507612809219,-0.3752879071422629,-0.46363589941495975,-0.10718092531428605,1.0146413381611152,0.22764890419787773,-0.9031793795175818,0.5324577550434368,-1.0196820541361158,-0.9344716279843737,-1.20403124258557,-0.6281234149031951,-0.34811029052350245,-1.1446136059778738,-0.6840972915142232,0.35939056264625546,-0.614932076152911,-0.8033405801859667,0.5091644252356594,0.22434698133037595,1.0270204962749092,0.4707044486428765,0.4654333117346222,0.938052296405421,0.23975178924528837,-0.7223801945050539,0.27129558863817466,-1.1941064017726584,-1.1366136069339992,0.08963648912084421,-0.2704077751834204,1.3396677828632066,-1.0061592083572137,0.29177363415170665,0.1861297390881969,0.5140260649569062,1.1851568412524103,0.4809377181435961,0.45919567543478745,-0.47111234891462095,-1.203928574904248,-0.6093861548125069,-0.6934155723923777,-1.2195117295336786,-0.25222227418296317,0.6426654340183043,0.7483652753024287,-0.2797918362986064,1.0203513368164066,0.9194155187045231,0.3598554237464566,1.0603968101576275,0.5897585204250998,-0.34480407658579937,-0.8112249321650644,0.7291294414198516,0.3074289314813656,0.6988893316230815,-0.6242075499180846,-0.5918014122122011,0.14940552844405272,-0.08376273247865446,-0.663779700467823,-0.2668100880257207,0.7639686544141826,0.7679188200557434,-0.7177735216823589,-0.3959977707304117,0.984077904876077,-0.6442601204450584,-0.3196825926579318,0.9235150606273697,0.5729653129272085,0.25182998960959774,-0.608777923085442,-0.8536990697230256,-0.9382526206549507,1.0550507422638475,-0.5603275598759785,-0.8302794344271198,0.08467080201795747,0.20056934060756776,-0.8167698175956573,-1.0060028948477029,-0.026945638031042163,0.6755352919950189,-0.10920369324251025,-0.03605993845359373,0.5435327262965619,-0.2721674115861271,0.6627047173847266,-0.3961700860020362,0.007851933241973894,0.3268373984812683,-0.9349505057016345,-0.8246784586439042,1.0113937126253796,-0.41430423354571533,0.4026582831767929,-0.9903070640120164,-0.8852700368447131,0.05654303266441059,-0.8873008162941566,-0.594207836923064,1.1467898681283633,0.8895197037064855,-1.304733457134864,1.0081083087806737,-0.6222085082453654,-0.9840256846467541,0.5261229394741709,-0.131808769639306,0.5326060038966376,-0.010743837212120466,1.2223025559593792,0.7882547945709615,-0.40657895921305254,-0.9858547023029316,0.9938727476777858],\"type\":\"scatter\",\"uid\":\"4f225a59-3a46-4aaa-ad9e-b476e92c023b\"},{\"marker\":{\"color\":\"blue\"},\"mode\":\"markers\",\"name\":\"1\",\"x\":[0.36229708363736,-0.2720771511382455,-0.6407251671474857,-0.5669382834509148,-0.2113209906694174,-0.030253203814796105,0.37443976155908415,-0.16355069238727143,-0.8017758227787288,-0.11891966555722128,0.33621266384962456,0.566086446738976,-0.16752959656018812,0.22866302138864963,-0.6721939012319226,0.23320828260965162,0.37401626316220266,0.7496771600345216,0.08092818377159824,0.5859142798113819,-0.18655492147952563,-0.39189422883345504,0.6027963944813616,0.2038440123001924,0.9812873728448694,0.4592356495171873,0.10254487649924007,-0.5303429338368646,0.09362819332496708,0.02379146816363743,0.49452978204516396,0.0503206809370424,-0.3416807987709494,0.01628637761262902,0.18838920597864206,-0.4029461660645834,-0.0575468325208677,-0.1288063866833417,0.4109190929780921,0.3129851496666628,-0.5669419608357616,0.16286967627450127,-0.11539795108821363,-0.05069237898891821,0.3446232842368996,0.9308900023282647,-0.5742735264034422,-0.7573342122717596,0.8051205248262183,-0.47854101008967154,-0.5618847845239704,-0.020523967771106877,-0.3402595935021628,0.36589081429594633,-0.06373391094948484,-0.45616094372751637,0.31879655406359353,0.4710609610803746,-0.05977886271745325,0.5693144528493591,-0.5215213358996549,0.1385702395901363,-0.6015359818879933,0.3902649740857546,0.1497426130029485,0.19533150126444443,-0.5400107485564426,0.3165511080297278,0.33432568014670494,0.12337214740857017,-0.6744012114725784,0.30315172294469384,0.08416238521468658,0.6829788662436684,0.13080040620166017,-0.2337438883515788,0.008628650293045742,0.3464273294440481,-0.4636781229759999,-0.14974850557567218,-0.25317752774064683,0.3112388787920203,0.4774563792369552,-0.21632404875647354,0.19538039860604872,-0.5120994894096779,-0.2475084461935293,0.11625416996892518,-0.48238775072028506,-0.014662069245142621,-0.07062043836063964,-0.259671186006548,0.45008798333445904,-0.34367908998493035,-0.196360677887934,-0.23280423151139662,0.4009576967036307,-0.5460540565384802,0.5193952941787054,-0.8401592324896587,0.15102132367575488,-0.14346990642294224,0.034481090124469094,0.0899540373204096,0.506347397712424,-0.24371351313797057,0.46911149553248077,-0.42422572159127675,0.4280462928541321,0.332215354558695,-0.4471189731223,0.23851285818696083,-0.31824145030276174,0.31039361611219307,-0.1609256878640341,0.14302245289580867,0.04844354777067361,-0.6651912597869597,0.42169103181129897,0.1695028101442752,0.32680467762454274,0.5406019641835997,0.5283552560599211,0.5214861233733997,0.37416135155119445,1.0399227824197763,0.6788579841303269,-0.7810359310204109,0.5615656807811933,-0.771243855225029,0.0869034188673572,0.5606718775727981,0.40782229573636253,0.49998189830043427,-0.9048473709933341,0.19897625878569802,-0.3392351743639799,-0.10303955869989675,0.03675578994611445,0.45254492624764475,-0.05121761428250715,-0.24300311722839607,0.33923311792214467,-0.42147547671222235,-0.672952687945992,0.47262850100744536,0.502111748362165,-0.7557210989851633,0.7093445476319105,0.08666903627706907,0.46903063580516674,-0.5602157838575895,0.16943464742504868,0.754510153395447,0.4736610191638634,0.28246879611693304,0.1521102102040055,0.45815093756238245,0.08847279172829661,-0.23458318170996426,-0.6748537578557962,0.07554717531435452,-0.23026458881231388,0.4417910879538,-0.4962102579185627,-0.2547176259687692,-0.4214714364857577,0.4194169667371302,-0.18058035337211736,0.10790835759264222,0.2730536293417372,0.5229926224939047,0.27968238341137397,0.020513372145528924,0.5663670952415643,0.2633445237378024,0.2829508150107355,-0.6201184361469257,0.28863900140637,-0.37190283458973145,-0.6004379762254538,0.22299680890133752,-0.39635429036942893,-0.9371054353169154,-0.07684730693546504,-0.0776542410385449,0.6040798929938642,-0.6707356775603202,-0.46267599397451026,0.22732895080413654,-0.5237683007427474,0.3982231574937729,0.43516751843701673,0.3842256421512681,0.21654564350949776,-0.3594521294638999,0.10013124492032086,0.7317103489349592,0.029388128283180104,0.09294932147427457,-0.4055606249027892,-0.6528332310065283,-0.4558218718237508,-0.04617927687544654,-0.20191103351222006,0.35916474943945176,-0.49821009853105913,0.16779433123414875,-0.23766108671983555,-0.08129184814716586,-0.28487933422810635,0.21216758023694787,0.5069823512502226,-0.44043209758802415,0.4829891968849694,0.42473230756242775,0.1925654301195609,-0.4486372026513689,-0.21837954039404123,0.22200248704378142,0.1499728374071306,-0.4362634700198344,0.42494162251514844,-0.19685688290600611,0.21854233889157482,0.5851130713917547,0.3120911648257777,0.5520217130697462,0.5196156769336495,0.6454602928144136,0.6591917699697138,-0.0006129658043831365,0.19427827363365405,0.31069194016071033,0.28896846545171023,0.2460112943398865,-0.07834817703711869,-0.7807443497478821,-0.25367786219154365,0.08506287326750828,-0.8929685274658371,0.29761977581716326,-0.3580667469070927,0.24287828576525744,-0.26666191317620896,0.36473107130010285,-0.6051761285442998,0.09150172763823317,-0.3205541505181115,0.5046327378959253,-0.11977132047218042,0.11598871632919831,0.3842539354278005,-0.5050797019430213,0.3225772243707366,0.6524158572238437,-0.10685188144424212,0.042497214930318716,-0.4965002656583147,0.6147548373094487,0.6474039152030437,-0.53771554841008,0.4037024832221975,-0.3175292430925616,-0.22227357756894436,0.26249580081820917,0.8585450403680828,-0.4074380361842146,-0.4380872594953642,-0.3269724297749389,0.5642164202549008,-0.2969844056592143,0.3115552361053919,-0.10183904809709274,-0.16302003653980857,-0.2934312225761567,-0.6153885510997441,0.25365823492260536,-0.3095804510618081,-0.32280998900315516,-0.3388560473780061,-0.4601734715300882,0.07172899574916461,-0.03963113337795837,-0.0535120296195013,-0.8193422056934223,-0.1790623402872652,0.3029450310261128,0.1870848270866484,-0.24375698214265346,-0.07576517501840208,-0.1997081139030096,-0.6743790433800322,-0.5353731501301555,0.4313732333802022,0.5734809137264765,0.7857433208732756,0.18608178009618054,-0.192559716190109,0.4542437052856765,0.56319369847278,0.4399544542633519,0.3353132949786849,0.23452223009233256,-0.5399382941234852,-0.2629751069017017,0.60301355700314,0.26651193283825936,0.5547983444388649,0.49896539575945764,-0.07820078466960756,-0.4070938191639753,-0.5466072674938925,-0.5222987983630971,0.10219685639421015,0.5938404370616507,0.8305820303856273,-0.4566835385742417,0.22004325606833788,0.5657295972321821,-0.16567830871557615,-0.5981407015833473,0.4474158225665442,-0.6918942151364742,-0.38588902249201135,-0.5091940015834291,0.23645047613134493,-0.48531393095112557,-0.49806690385026336,0.49104820866639876,0.11310971032660491,-0.23951803736121358,-0.7070062736831472,-0.3649025684945743,-0.20152922320122496,-0.5889513742404057,0.30781682674118,-0.2923392096021661,-0.43408617678142203,0.027502376489840635,0.06876709805483631,-0.31611075804766486,-0.04559640742682092,0.6307008439502146,0.6432997491851293,0.15183485108849645,-0.07347551483579745,0.5139200534866827,-0.5772228136188803,0.0218900472128285,-0.019575324534800723,-0.04740734635310806,0.10390838075135433,0.1212124289520382,0.02013426939030505,-0.4753644060446426,-0.14069419180687606,-0.411811426045141,0.07670565108984471,-0.20489557081487836,-0.2863784609110861,-0.43697523038907604,-0.7222687216981167,0.08202935656469973,-0.032807252843213855,0.11563883060654453,-0.3088228187533547,-0.5529112435806611,0.20799223499668085,0.15201997938505943,0.19920128712607832,-0.5279762630222381,0.4562574074707361,0.810561376080574,-0.285226593026176,-0.28717155517622983,-0.32595981508592187,-0.16877747093923778,-0.02617280897742888,0.4116977618428467,-0.2560571700020353,-0.6008147533645377,-0.044034116470056506,0.1670903195498157,-0.03318693607462572,-0.7838615006613424,-0.3427835077215067,-0.028039525988223284,0.0636867457609902,0.6114686394254014,-0.7791387195702412,0.04431411239107497,-0.16667728563397055,0.3447161191503373,0.6432263847815857,0.045053544312391225,0.1450815693761951,-0.16549046174802187,-0.5255703851618292,-0.05658202342028004,-0.09955209466258082,0.44636272706836383,0.16913795108590018,0.049630944443595726,-0.2944603906321104,-0.6148112225534786,0.47819288759795897,0.6064590084298837,-0.29094597436820563,0.05354082458228974,-0.022563030924331998,-0.162729172390949,0.2964659732161178,-0.6319620357945457,0.4610666384964309,-0.5144534721911208,0.10665481759765194,-0.0859898811221913,0.39187390471373573,0.20501625868873707,-0.3315828772276594,-0.4938773448990489,-0.325643913200242,-0.4377610530780477,-0.0858995360593949,0.5522374518687737,0.16261407804512537,-0.21858392311628683,0.2767477962129834,-0.7807824574920192,-0.2902251600768294,-0.279384991483182,-0.6402827424859465,0.4598199263261354,0.42766381075672855,-0.5404107790919583,-0.21632957071571476,-0.15904050158321303,-0.34296647571698846,-0.3391324881096349,0.37417254970614944,-0.04041503715600289,0.15973936428980984,0.6783702585336858,-0.21752602291185558,-0.017768521850200836,-0.19255326992587296,-0.9715978583087637,-0.5775907158964103,0.17367138365884036,-0.1359974579817057,-0.510127312886644,-0.42482174309186793,-0.631597890733894,-0.6073106111220705,0.2988740919818298,-0.09231741268362298,0.16223111453279837,0.29880905355496923,-0.3744794667181094,-0.6488587695332337,-0.37269865500406146,-0.5841059425213381,0.6449931478949,0.1856218976719247,0.13777281945427555,0.5498437824162605,-0.1758117437452032,0.7354577879388836,0.1452319203014406,0.28140301358864,-0.5506258180024153,0.490001083249995,-0.14105303594412047,0.35775454137143925,0.2105820762964576,-0.005297514094248501,0.20420766849816208,0.782772560899334,-0.23171997756776558,0.36843278727616363,-0.3435588191616523,0.5178368417119047,-0.12543369964587425,-0.29397395358371725,-0.7238567826907836,-0.419338192257073,0.3579800254295037,0.7143291542161367,-0.25809714196888767,-0.3911038567249498,0.28854983233145354,-0.17228127352984704,-0.5636961750633767,-0.4161196502430705,-0.2073689409458405,-0.08132608854420176,0.28608048460687846,-0.2014628788544592,-0.006992713803157816],\"y\":[0.28247097207202054,0.23564621245770895,0.5494362324626353,0.24588771242615076,0.7091710350833498,0.5227064141445041,0.19898428628957027,-0.553738930405392,-0.27467096797171686,0.7554411994807855,-0.612475753786671,-0.5200339773485186,-0.47422158864453534,-0.4783514193127716,-0.01150689309745951,0.20871177707762323,0.24717388399735443,-0.17643904113676606,-0.5820244226158333,-0.11421831704114221,0.39678560330872564,0.3651509255946945,0.5531468011471204,-0.3851258194346776,-0.05568127148204574,-0.8723171001542183,0.6030602750694554,-0.4962152573851361,0.35544928804198866,-0.7631974873433978,0.04631690153868756,0.5291267046813236,-0.35424929666879096,0.0036835852803662195,0.431726565742164,0.438558885903458,0.18161290885368014,-0.5107236198426063,0.2632164937961848,0.24176178210401056,0.01058498212602231,0.27007739508517997,0.8026400126357294,0.038609741395868646,0.5528433160563218,0.12188640916108592,0.13492927652361206,0.0013183931158430688,0.4505748948108904,-0.06287295846227889,-0.04779985690837968,-0.5849251831314457,-0.1435269530850955,-0.3243471531341604,0.36430358550096753,0.683240306483079,0.36234976576785416,-0.3133341252493685,-0.5120379806330813,0.27884048346136875,-0.21109869785496385,0.13513638323042132,-0.41400560248082224,-0.009887640999969555,0.1956068090290851,-0.5312885369772551,0.40149509055882704,0.36466334822444996,0.04602478933358617,-0.4408690674116068,-0.17679193397452084,0.4829525951221212,-0.6102355105233968,0.031377132929370215,-0.17351386064220414,0.5024276509141685,-0.6070483157051557,-0.5657197125021333,-0.3758965320894031,-0.18343802836678946,0.3465394238079993,-0.10957006574755997,-0.12094447327941815,0.11879304826410175,-0.7089710144268234,0.2908435945154234,-0.037376544757652536,0.2510690439467823,0.5680379686770849,-0.43494648658178725,0.513100312879278,0.5183158392498837,-0.06821219510663676,-0.38424110031374803,0.4065860093805388,0.5038664324264929,0.19539965877717036,-0.2718852507314798,-0.11699213365269295,-0.07501555539757619,-0.3395132131447837,-0.2213022401697459,0.7246473683556716,0.4484453518228866,0.16687835866325978,0.4632200109323602,0.44979574330637917,-0.3764964606356808,0.5654453846322055,-0.580243231476488,-0.40364129871343196,-0.4095863064643712,-0.5493982368342682,0.3657150073426687,0.5369200460038438,-0.5407738240775591,0.24729098292891655,0.10738703689079107,-0.1717361862841466,-0.6952173748998571,0.17359065070587593,-0.3955793254899523,0.3548468993969236,0.15236569143580003,0.8410099020228912,-0.2435173893696602,0.2621432392114678,-0.46910650091824835,-0.11472618823543862,-0.24543653642696384,-0.273335564482313,0.100880543085824,-0.6842450891547027,-0.5569137228367345,0.16908427696110273,-0.5159713266211674,-0.023886773774618952,0.38838982723722154,-0.47366990764139427,0.35968289960854927,0.6098674676949033,-0.2342453937772157,0.26063626336756507,0.12224364519232694,0.33513481004530443,-0.006856316308226307,-0.24273555471047958,-0.45994162391517907,0.12027308100995278,-0.6932324568283174,0.10634049613314414,-0.17630854063642068,-0.6055116619812283,0.5531999052349403,-0.253662825180201,0.4513874786522649,0.573153258705325,-0.006007360278007967,0.22864276583884519,0.1337304443989335,0.24668342820717,0.5274878180492752,-0.0896154617521209,0.11790184602934436,0.38562716349785536,0.16634817794618906,0.015917934205737033,0.25180428948558553,0.587266627440457,0.3319880531169864,-0.8367069240726828,0.19527007393456444,0.26445810370790906,-0.4626751746284765,-0.3251181177007147,-0.09498301306136242,0.667573974745038,-0.19028578080830758,-0.705551498639174,0.2676032963223178,-0.015875687653142602,-0.41831407922492364,-0.31625205419436103,-0.2390202434356938,-0.5410722030527011,0.0586538628267006,-0.3191663410064564,-0.06508269791200469,0.17249432920171476,0.30117437580075124,0.1539482893810546,-0.253053462170138,0.2004892250757167,0.18685092200690268,0.33877876835967036,0.09980169514496057,-0.4069712918665631,-0.1286554694747281,0.010865838232269193,-0.8774386644694079,-0.14847077531431027,-0.45431518932140785,0.4251467576481569,0.6200215171495211,-0.2688634773959965,0.1458144189697399,0.2308982133131935,0.6368879553374622,0.6692614897012072,-0.754838984825678,0.10648064799300633,0.32685295652338164,-0.21697489054405777,0.651966972881797,0.321093093452268,0.26603425688489124,0.46946693810220247,0.538733421004759,0.4178286303130821,0.42097469007837346,-0.38425999188334803,0.5124915350637327,-0.3713475792769115,0.605542972680393,0.19139367589144357,0.05394882110664931,-0.2643156283452818,-0.4998561823860837,-0.21270027205314382,-0.041441090803188696,-0.18168250304256678,0.6498615997567991,0.7225976480314615,0.36242905164941774,0.17440463873042503,-0.8874329853972001,0.5390957976937811,-0.2725575081173098,-0.5093421952471527,-0.5737576149408782,0.35307563977805606,-0.564390190091633,-0.2329187646104101,-0.41936800492223836,0.3245339396213866,0.05103364396299431,-0.009086927593194035,0.02446178336359775,-0.23401688516975094,-0.036422331696050345,0.3451766696897066,0.040354302759362026,0.13314910759708687,-0.4435584980828644,0.29213879862941616,0.3444085609913361,0.620140178208191,-0.6162115928800435,-0.022826746282139584,-0.22094415327398598,0.036748502919050685,-0.3809642537112916,0.5863251593082076,0.48047382650785975,-0.4535914553903374,-0.39867308454456224,0.0385080356762709,-0.3158034094226286,0.14835011339832227,0.6657024806529115,-0.3751639697987893,0.032854108012352085,-0.36988628089219167,0.6555062481629889,-0.6010161734249235,-0.10738468072299526,-0.16615940056909367,0.254218831319293,0.043615122707525544,-0.33096105594501746,0.5820790793635731,0.03827372446479662,-0.5939851483150947,0.49763384363838664,0.32196776680394756,0.19977240513809316,0.36669524232477996,-0.21134520503154078,1.0343125283993961,0.34822909308990135,-0.27903907784948323,0.5797061913652438,0.32298382097776257,0.3705166282177307,-0.6109715401248859,0.1346713884822735,0.022373740672704923,-0.49192431548591703,-0.89100321766052,0.07026879633012643,0.36796750728808836,-0.3783715107506709,0.05482434820879662,-0.22990218922662375,0.06510747893628877,-0.8714405029665309,-0.3816716376548936,-0.22022331923060912,-0.24655129257494998,-0.04966549783244187,-0.34820899298321095,0.12424033202182921,-0.5841668710721929,-0.33616094727082046,-0.2377658348178976,0.18796539422835756,-0.3389842461733236,-0.6410812706615934,0.7054485039861045,-0.09794844287675761,-0.2233714284461501,-0.0025479928056012513,-0.28681745442590395,-0.11742658688302404,0.2085742136452944,-0.22933294290418066,0.3460045604712373,-0.10221059882289044,0.34293568175139283,-0.726504250275428,0.5077110678560143,-0.2145717482550995,-0.24979472137794034,-0.22950250347773415,0.94038186852278,-0.23004425822410282,0.2756899939397746,0.5480270940995438,0.4659587205273478,-0.4339032483982337,0.2566253035937958,-0.37484372590295817,0.007194575881991849,-0.5462258735760699,0.22651306102953833,-0.1968467835792711,0.13577939425829766,-0.16099010305626646,-0.08052047051800933,0.3487415978938865,-0.3910826544678729,0.5309974775789923,-0.5783232814162992,0.4629738103690996,-0.403629026276431,-0.08906291267322881,-0.22191607413106806,-0.3711459149694383,-0.2935839676068214,0.5321443711367674,-0.09529797529763462,0.14959681201152866,0.10674429636137298,-0.2660849578937384,0.3004290991973685,-0.43507754374751056,-0.21913889343907955,-0.09841042657665339,-0.5810050488663414,0.40232112265545866,-0.6327045974978505,0.1263277162955942,0.22401689969274746,-0.20919106005000876,-0.36754712964367175,0.3126712467888591,-0.5404699632601221,0.20396390937739506,0.3547456238321928,0.3025117199136198,-0.38459550391385666,-0.2964823465502653,0.5627959532459765,0.326979385851727,-0.7617680471928885,0.27016735198494074,-0.44431423065739534,0.5028459399605079,0.4897306440936075,-0.42688371228242084,-0.30903978170147967,-0.1558624667166978,0.45635736721755527,-0.24071914331387811,-0.4146560424400911,-0.47312213832663563,0.5089047254725486,-0.6142949142984062,-0.4284914838422391,0.28545556208395806,-0.18456552010294003,0.24961087500129475,0.058401594691549874,0.5814787057093633,-0.31526711808231034,0.27280085398148207,-0.17674308000379937,0.1173495151720083,0.4505577505297514,-0.7375720913273108,-0.41304462613050413,-0.402998156175234,-0.6470005708064357,0.13741447124291561,0.2395386295146394,-0.19848392825561229,0.5669539572913116,0.5773301745291541,0.6213808329352515,-0.5348384766407085,-0.11976661503662939,-0.19717096839196513,-0.403696530884583,-0.08205429283945781,0.6061803922800852,-0.5076844569485347,0.1774198706227586,-0.17385345308325284,0.15365527062051607,0.16102361266918613,0.33508783851578117,0.21299872808464138,0.3340860768703834,0.3388801787044452,-0.6817209306660078,-0.08942989331313835,-0.30777436768202415,-0.41448235111381504,-0.6481496444100832,0.6348943197304018,0.5735492321749882,0.3671370957634175,0.010066179910103917,0.2850179533466599,-0.6381560887055614,-0.1983792092304537,-0.36616718060930287,-0.09629377023873968,0.042520406856592474,-0.6999321516213102,0.020552327164606775,0.24369436138840717,0.43782341812983533,0.08636737455161839,0.30293974858357536,-0.24548079867386338,-0.6675033823018359,-0.6670311779543638,0.2860478334175652,0.09972389735377724,0.38782810767834397,-0.49483855035410285,-0.46411106352715803,0.2418121512070492,-0.48832473436351587,-0.1377437217296126,0.08963569816343725,0.09504286962776948,0.25291600553438015,-0.5321820631736612,0.03544346483932681,-0.07638130945409305,0.3770390432814732,-0.3388251776179833,-0.22428427859514535,0.42253015697325114,-0.1777069392691451,-0.08298998761554395,0.16139005972700657,-0.08310980173394,0.5220500323014061,-0.4430262713019165,0.2973966598400524,0.4883918449261674,-0.39915161497808227,-0.10815367703481527,0.026520388715801257,0.06348521831724338,0.13862362409869877,-0.5842874812560397,-0.18892686662240887,-0.0668063522945862,-0.7467651706299407,0.19993148246904113,0.5566583349441874,0.7929960590585086,-0.4143752550534997,0.7062744831145341,0.24564641288676634,-0.6523571371143053],\"type\":\"scatter\",\"uid\":\"d221a303-9861-436b-83d8-d29f190d9601\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"range\":[-2,2],\"title\":{\"text\":\"Feature 1\"}},\"yaxis\":{\"range\":[-2,2],\"title\":{\"text\":\"Feature 2\"}},\"width\":500,\"height\":500,\"title\":{\"text\":\"make_circles Dataset\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d9061350-1b45-4435-986e-b887373b9c2b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first 5 training datapoints: [[ 0.36229708  0.28247097]\n",
            " [-0.27207715  0.23564621]\n",
            " [-0.64072517  0.54943623]\n",
            " [-0.56693828  0.24588771]\n",
            " [ 0.47106162 -0.88152647]]\n",
            "The labels for the first 5 datapoints: [1 1 1 1 0]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_circles\n",
        "X, y = make_circles(n_samples=1000, noise=0.2, factor=0.5, random_state=42)\n",
        "data_fig = go.FigureWidget()\n",
        "data_fig.add_trace(go.Scatter(x=X[y == 0,0], y=X[y == 0,1],\n",
        "                             mode='markers', marker=dict(color='red'),\n",
        "                             name='0'))\n",
        "data_fig.add_trace(go.Scatter(x=X[y == 1,0], y=X[y == 1,1],\n",
        "                              mode='markers', marker=dict(color='blue'),\n",
        "                              name='1'))\n",
        "data_fig.update_layout(width=500, height=500,\n",
        "                       xaxis_range=[-2,2], yaxis_range=[-2,2],\n",
        "                       xaxis_title='Feature 1',\n",
        "                       yaxis_title='Feature 2',\n",
        "                       title='make_circles Dataset')\n",
        "data_fig.show()\n",
        "print(\"The first 5 training datapoints:\", X[:5])\n",
        "print(\"The labels for the first 5 datapoints:\", y[:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_tensors(X, y):\n",
        "  from torch.utils.data import random_split, TensorDataset\n",
        "  data = TensorDataset(torch.tensor(X, dtype=torch.float32),\n",
        "                       torch.tensor(y, dtype=torch.long))\n",
        "  torch.manual_seed(140)\n",
        "  train_data, test_data = random_split(data, [0.8, 0.2])\n",
        "  return train_data, test_data\n",
        "\n",
        "training_data, test_data = make_tensors(X, y)"
      ],
      "metadata": {
        "id": "9KdI9bhIDe4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LogisticRegressionModel, self).__init__()\n",
        "    self.linear = nn.Linear(2,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    p = torch.sigmoid(self.linear(x))\n",
        "    return torch.cat([1 - p, p], dim=1)"
      ],
      "metadata": {
        "id": "TnK7qjzzJpyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Rq6obpipKFzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary_pytorch(model, num_points=100, probs=True):\n",
        "  xx, yy = torch.meshgrid(torch.linspace(-4,4,num_points),\n",
        "                          torch.linspace(-4,4,num_points),\n",
        "                          indexing='ij')\n",
        "  grid = torch.cat([xx.reshape(-1,1), yy.reshape(-1,1)], dim=1)\n",
        "  with torch.no_grad():\n",
        "    preds = model(grid)\n",
        "    num_classes = preds.shape[1]\n",
        "    if num_classes > 2:\n",
        "      preds = torch.argmax(preds, axis=1).reshape(xx.shape).T\n",
        "      return go.Contour(x=xx[:,0], y=yy[0], z=preds,\n",
        "                        colorscale=[px.colors.qualitative.Plotly[i] for i in range(num_classes)],\n",
        "                        opacity = 0.5, showscale=False)\n",
        "    else:\n",
        "      if probs:\n",
        "        preds = preds[:,1].reshape(xx.shape).T\n",
        "      else:\n",
        "        preds = (preds[:,1] > 0.5).float().reshape(xx.shape).T\n",
        "      return go.Contour(x=xx[:,0], y=yy[0], z=preds,\n",
        "                        colorscale=[[0,'red'], [1,'blue']],\n",
        "                        opacity=0.5, showscale=False)\n"
      ],
      "metadata": {
        "id": "1kK4Ar1QKJl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_model(train_dataset,\n",
        "                   test_dataset,\n",
        "                   model, loss_fn,\n",
        "                   pred_fig, loss_fig,\n",
        "                   batch_size=64,\n",
        "                   learning_rate = 0.01,\n",
        "                   nepochs=50,\n",
        "                   sleep_time=0.2):\n",
        "  import time\n",
        "\n",
        "  from torch.utils.data import DataLoader\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset, batchsize=batchsize, shuffle=False)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), learning_rate)\n",
        "\n",
        "  test_loss_curve = []\n",
        "  for epoch in range(nepochs):\n",
        "    for batch, (X,y) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred,y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      test_loss_sum = 0.0\n",
        "      for X_test, y_test in test_loader:\n",
        "        test_pred = model(X_test)\n",
        "        test_loss = loss_fn(test_pred, y_test)\n",
        "        test_loss_sum += test_loss.item()\n",
        "      num_test_batches = len(test_loader)\n",
        "      test_loss_curve.append(test_loss_sum/num_test_batches)\n",
        "\n",
        "      boudnary = plot_decision_boundary_pytorch(model, probs=True)\n",
        "      pred_fig.data[-1].z = boundary.z\n",
        "      loss_fig.data[0].x = np.arange(epoch+1)\n",
        "      loss_fig.data[0].y = test_loss_curve\n",
        "      if (sleep_time > 0):\n",
        "        time.sleep(sleep_time)"
      ],
      "metadata": {
        "id": "q0Is-zy_MIJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "From ipywidgets import HBox\n",
        "Pred_fig = go.FigureWidget(data=data_fig.data, layout=data_fig.layout)\n",
        "Loss_fig = go.FigureWidget()\n",
        "Loss_fig.add_trace(go.Scatter(x=[], y[], mode=lines, name=Train Loss))\n",
        "Loss_fig.update_layout(title=Test Loss))\n",
        "Loss_fig.update_layout(title=Test Loss, axis_title=Epochs, yaxis_title=Test Loss (BCE))\n",
        "Model = LogisticRegressionModel()\n",
        "Boudary = plot_decision_boudary_pytorch(model,probs=True)\n",
        "Pred_fig.add_trace(boudary)\n",
        "Display(HBox([pred_fig, loss_fig]))\n",
        "Optimize_model(training_data, test_data, model, loss_fn, pred_fig, loss_fig,nepochs=50)\n"
      ],
      "metadata": {
        "id": "ADsg8tTDxPYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetworkModel1(nn.Module):\n",
        "  def _init_(self):\n",
        "    super()._init__()\n",
        "    self.hidden1 = nn.Linear(2,8)\n",
        "    self.hidden2 = nn.Linear(8,8)\n",
        "    self.output = nn.Linear(8,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    X = torch.tanh(self.hidden1(x))\n",
        "    X = torch.tanh(self.hidden2(x))\n",
        "    P = torch.sigmoid(self.output(x))\n",
        "      return torch.cat([1-p, p], dim=1)"
      ],
      "metadata": {
        "id": "vQmA8hpIxjJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model):\n",
        "  for layer in model.children():\n",
        "    if isinstance(layer, nn.Linear):\n",
        "      Nn.init.xavier_uniform_(layer.weight)\n",
        "      Nn.init.zeros_(layer.bias)\n"
      ],
      "metadata": {
        "id": "CgHwdThUx_01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model = NeuralNetworkModel1()\n",
        "Initialize_weights(model)"
      ],
      "metadata": {
        "id": "WtF4e_U2yDsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import HBox\n",
        "\n",
        "model = NeuralNetworkModel1()\n",
        "initialize_weights(model)\n",
        "\n",
        "Pred_fig = go.FigureWidget(data=data_fig.data, layout=data_fig.layout)\n",
        "Loss_fig = go.FigureWidget()\n",
        "Loss_fig.add_trace(go.Scatter(x=[], y=[],mode=lines, name=Train Loss))\n",
        "Loss_fig.update_layout(title=Test Loss, xaxis_title=Epochs, yaxis_title=Test Loss (BCE))\n",
        "Boundary = plot_decision_boudary_pytorch(model,probs=True)\n",
        "pred_fig.add_trace(boudary)\n",
        "display(HBox([pred_fig, loss_fig]))\n",
        "optimize_model(training_data, test_data, model, loss_fn, pred_fig, loss_fig,\n",
        "               batch_size=16, learning_rate=0.001, nepochs=100, sleep_time=0)"
      ],
      "metadata": {
        "id": "Ssi3t6fsN4cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomeNeuralNetwork(nn.Module):\n",
        "  def __init__(self, input_size, output_size, layers, activation_functions):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList()\n",
        "    self.activations = []\n",
        "\n",
        "    current_size = input_size\n",
        "    for i, layer_size in enumerate(layers):\n",
        "      self.layers.append(nn.Linear(cirrent_size,layer_size))\n",
        "      self.activations.append(activation_functions[i])\n",
        "      current_size = layer_size\n",
        "\n",
        "    self.layers.append(nn.Linear(current_size, output_size))\n",
        "    self.activations.append('sigmoid')\n",
        "\n",
        "  def forward(self, x):\n",
        "    for i, layer in enumerate(self.layers[:-1]):\n",
        "        x = layer(x)\n",
        "        x = self.apply_activation(x, self.activations[i])\n",
        "    x = self.layers[-1](x)\n",
        "    p = torch.sigmoid(x)\n",
        "    return torch.cat([])\n",
        "\n",
        "  @staticmethod\n",
        "  def apply_activation(x,activation):\n",
        "      if activation == 'relu':\n",
        "          return torch.relu(x)\n",
        "      elif activation == 'tanh':\n",
        "          return torch.tanh(x)\n",
        "      elif actiation == 'sigmoid':\n",
        "          return torch.sigmoid(x)\n",
        "      else:\n",
        "          return x"
      ],
      "metadata": {
        "id": "7amunp1yynHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import HBox\n",
        "\n",
        "model = NeuralNetworkModel1()\n",
        "initialize_weights(model)\n",
        "\n",
        "pred_fig = go.FigureWidget(data=data_fig.data, layout=data_fig.layout)\n",
        "loss_fig = go.FigureWidget()\n",
        "loss_fig.add_trace(go.Scatter(x=[], y=[], model='lines', name='Train Loss'))\n",
        "loss_fig.update_layout(title='Test Loss', axis_title='Epochs', yaxis_title='Test Loss (BCE)')\n",
        "buodary = plot_decision_boudary_pytorch(model, probs=True)\n",
        "pred_fig.add_trace(boundary)\n",
        "display(HBox([pred_fig, loss_fig]))\n",
        "\n",
        "@interact(n_layers=IntSlider(min=1, max=5, step=1, value=2, description=\"Layers\"),\n",
        "          neurons_per_layer=IntSlider(min=4,max=64, step=4, value=8, description=\"Neurons/Layer\"),\n",
        "          activation_fn=Dropdown(options=['relu', 'tanh', 'sigmoid'], value='tanh', description=\"Activation\"),\n",
        "          learning_rate=FloatSlider(min=0.001, max=0.1, step=0.001, value=0.01, description=\"Learning Rate\"),\n",
        "          batch_size=IntSlider(min=1, max=128, step=10, value=10, description=\"Batch Size\"),\n",
        "          epochs=IntSlider(min=10, max=200, step=10, value=10, description=\"Epochs\"))\n",
        "def update_mode(n_layers, neurons_per_layer, activation_fn, learning_rate, batch_size, epochs):\n",
        "  layers = [neurons_per_layer]* n_layers\n",
        "  activation_functions = [activation_fn] * n_layers\n",
        "  model = CustomeNeuralNetwork(input_size=2, output_size=1, layers=layers, activation_functions=activation_functions)\n",
        "  initialize_weights(model)\n",
        "  optimize_model(training_data, test_data, model, loss_fn, pred_fig, loss_fig,\n",
        "                 learning_rate=learning_rate,\n",
        "                 batch_size=batch_size, nepochs=epochs, sleep_time=0)"
      ],
      "metadata": {
        "id": "0HMl17kX0-aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_blobs(n_samples, centers, std):\n",
        "  from sklearn.datasets import make_blobs\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  X, y = make_blobs(n_samples=n_samples, centers=centers, cluster_std, random_state=42)\n",
        "  scaler = StandardScaler()\n",
        "  X = scaler.fit_transform(X)\n",
        "  return X,y"
      ],
      "metadata": {
        "id": "2xzhZ1JA7rA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = generate_blobss(n_samples=100, centers=3, std=1)\n",
        "blob_data_fig = go.FigureWidget()\n",
        "blob_data_fig.update_layout(width=500,height=500,\n",
        "                            xaxis_range=[-3,3], yaxis_range=[-3,3],\n",
        "                            xaxis_title='Feature 1',\n",
        "                            yaxis_tite='Feature 2',\n",
        "                            title='make_blobs Dataset')\n",
        "for i in np.unique(y):\n",
        "  blob_data_fig.add_trace(go.Scatter(x=X[y == i, 0], y=X[y == i, 1],\n",
        "                                     mode='markers', marker=dict(color=px.colors.qualitative.Plotly[i]),\n",
        "                                     name=str(i)))\n",
        "blob_data_fig.show()"
      ],
      "metadata": {
        "id": "b1KemNdN8MOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BlobNN(nn.Module):\n",
        "  def __init__(self, input_dim, num_classes, hidden_dim=16):\n",
        "    super().__init__()\n",
        "    self.hidden = nn.Linear(input_dim, hidden_dim)\n",
        "    self.output = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.hidden(x))\n",
        "    logits = self.output(x)\n",
        "    return torch.softmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "TChaeEod_Cx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BlobNN(2,3)\n",
        "initialize_weights(model)\n",
        "\n",
        "blob_red_fig = go.FigureWidget(data=blob_data_fig.data, layout=blob_data_fig.layout)\n",
        "blob_loss_fig = go.FigureWidget()\n",
        "blob_loss_fig.add_trace(go.Scatter(x=[], y=[], mode='lines', name='Train Loss'))\n",
        "blob_loss_fig.update_layout(title='Test Loss', xaxis_title='Epochs', yaxis_title='Test Loss (CE)')\n",
        "boudary = plot_decision_boudary_pytorch(model)\n",
        "blob_pred_fig.add_trace(boudary)\n",
        "display(HBox([blob_pred_fig, blob_loss, fig]))\n",
        "\n",
        "@interact(n_samples=IntSlider(min=100, max=1000, step=100, value=500, description=\"Samples\"),\n",
        "          centers=IntSlider(min=2, max=5, step=1, value=3, description=\"Centers\"),\n",
        "          std = FloatSlider(min=0.5, max=5.0, step=0.5, value=1.0, description=\"Std Dev\"),\n",
        "          epochs=IntSlider(min=10, max=200, step=2, value=20, description=\"Epochs\"),\n",
        "          learning_rate=FloatSlider(min=0.001, max=0.1, step=0.001, value=0.01, description=\"Learning Rate\"))\n",
        "def update_model2(n_samples, centers, std, epochs, learning_rate):\n",
        "  X, y = generate_blobs(n_samples=n_samples, centers=centers, std=std)\n",
        "  blob_pred_fig.add_trace(go.Scater(x=X[y == i,0], y=X[y == i,1],\n",
        "                                    mode='markers', marker=dict(color=px.colors.qualitative.Plotly[i]),\n",
        "                                    name=str(i)))\n",
        "  train_data, test_data = make_tensors(X,y)\n",
        "  model = BlobNN(2, centers)\n",
        "  initialize_weights(model)\n",
        "  boundary = plot_decision_boudary_pytorch(model)\n",
        "  blob_pred_fig.add_trace(boudary)\n",
        "  optimize_model(train_data, test_data, model, loss_fn, blob_red_fig, blob_loss_fig,\n",
        "                 nepochs=epochs, learning_rate=learning_rate, sleep_time=0)"
      ],
      "metadata": {
        "id": "SNvMs7st__Ui"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}